{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy;\n",
    "# pip install pandas;\n",
    "# pip install matplotlib\n",
    "# pip install tensorflow\n",
    "# pip install pydot\n",
    "# pip install mlxtend\n",
    "# pip install opencv-python\n",
    "# pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import glob\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from PIL import Image\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2 as cv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directories of training , testing & validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=\"chest_xray/\"\n",
    "train_directory= input_data + \"train/\"\n",
    "val_directory= input_data + \"val/\"\n",
    "test_directory= input_data + \"test/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = train_directory\n",
    "class_names=os.listdir(train_directory)\n",
    "print(class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir to generate files\n",
    "FILES_GENERATED = 'files_generated/'\n",
    "# name of model to save to png file\n",
    "MODEL_PNG = 'cnn_model.png'\n",
    "#checkpoint dir\n",
    "CHECKPOINT_DIR = 'checkpoints/'\n",
    "# name of best model to save\n",
    "MODEL_SAVED = 'saved_model/best_model.h5'\n",
    "# Default batch size\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to display random images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_random_image(target_directory, target_class):\n",
    "    target_folder = target_directory + target_class\n",
    "    random_image = random.sample(os.listdir(target_folder), 1)\n",
    "    img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(target_class)\n",
    "    plt.axis(\"off\");\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    r=random.randint(0,1)\n",
    "    img = view_random_image(data_dir, class_names[r])   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random vizualization from all directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(15, 7))\n",
    "ax = ax.ravel()\n",
    "plt.tight_layout()\n",
    "\n",
    "for i, _set in enumerate(['train', 'val', 'test']):\n",
    "    set_path = input_data + _set\n",
    "    ax[i].imshow(plt.imread(set_path+'/NORMAL/'+os.listdir(set_path+'/NORMAL')[0]), cmap='gray')\n",
    "    ax[i].set_title('Set: {}, Condition: Normal'.format(_set))\n",
    "    ax[i+3].imshow(plt.imread(set_path+'/PNEUMONIA/'+os.listdir(set_path+'/PNEUMONIA')[0]), cmap='gray')\n",
    "    ax[i+3].set_title('Set: {}, Condition: Pneumonia'.format(_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. of images present in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _set in ['train', 'val', 'test']:\n",
    "    n_normal = len(os.listdir(input_data + _set + '/NORMAL'))\n",
    "    n_infect = len(os.listdir(input_data + _set + '/PNEUMONIA'))\n",
    "    print('Set: {}, Normal images: {}, pneumonia images: {}'.format(_set, n_normal, n_infect))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras ImageDataGenerator\n",
    "\n",
    "<p> It is used for getting the input of the original data and further, it makes the transformation of this data on a random basis and gives the output resultant containing only the data that is newly transformed. It does not add the data. Keras image data generator class is also used to carry out data augmentation where we aim to gain the overall increment in the generalization of the model. Operations such as rotations, translations, shearin, scale changes, and horizontal flips are carried out randomly in data augmentation using an image data generator. </p>\n",
    "\n",
    "![ImageDataGenerator](http://ai.stanford.edu/blog/assets/img/posts/2020-04-20-data-augmentation/fig1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how it looks like\n",
    "![ImageDataGenerator_sample](https://miro.medium.com/max/1200/1*Ukc49J8TzyxiOD30EqOWwQ.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_gen = ImageDataGenerator(\n",
    "        rescale = 1/255,\n",
    "        shear_range=10,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        brightness_range=[0.5,2.0],\n",
    "        width_shift_range = 0.2,\n",
    "        rotation_range=20,\n",
    "        fill_mode = 'nearest'\n",
    ")\n",
    "val_Datagen = ImageDataGenerator(\n",
    "        rescale = 1/255\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow from directory\n",
    "\n",
    "<p> This method is useful when the images are sorted and placed in there respective class/label folders. This method will identify classes automatically from the folder name. </p> \n",
    "\n",
    "![Flow from directory](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*HpvpA9pBJXKxaPCl5tKnLg.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Image_gen.flow_from_directory(\n",
    "    train_directory,\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    )\n",
    "\n",
    "validation = Image_gen.flow_from_directory(\n",
    "    val_directory,\n",
    "    batch_size=2,                                              \n",
    "    class_mode='binary',\n",
    "    )\n",
    "\n",
    "test = val_Datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    batch_size=2,\n",
    "    class_mode='binary',                         \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping \n",
    "\n",
    "<p> In machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient descent. Such methods update the learner so as to make it better fit the training data with each iteration. Up to a point, this improves the learner's performance on data outside of the training set. Past that point, however, improving the learner's fit to the training data comes at the expense of increased generalization error. Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit. Early stopping rules have been employed in many different machine learning methods, with varying amounts of theoretical foundation. </p>\n",
    "\n",
    "![Early stopping](https://i.stack.imgur.com/LY2wM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReduceLROnPlateau\n",
    "\n",
    "<p> Reduce learning rate when a metric has stopped improving.\n",
    "\n",
    "Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced. </p>\n",
    "\n",
    "![ReduceLROnPlateau](https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/images/lr1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                          patience=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50V2 model\n",
    "**Reference**\n",
    "\n",
    "[MathWorks resnet50](https://www.mathworks.com/help/deeplearning/ref/resnet50.html)\n",
    "\n",
    "<p> ResNet-50 is a convolutional neural network that is 50 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database . The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals. </p>\n",
    "\n",
    "![ResNet50](https://www.researchgate.net/publication/363920620/figure/fig2/AS:11431281086998031@1664428512125/Resnet50v2-and-LSTM-based-visual-baseline-models-architecture-The-size-of-the-feature.ppm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    resnet_model = tf.keras.applications.ResNet50V2(\n",
    "        weights='imagenet',\n",
    "        include_top = False,\n",
    "        input_shape = (224,224,3)\n",
    "    )\n",
    "\n",
    "    for layer in resnet_model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "    x = resnet_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "    # output layer\n",
    "    predictions = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "    res_model = tf.keras.Model(inputs=resnet_model.input, outputs=predictions)\n",
    "\n",
    "    # Compiling the model\n",
    "    res_model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    return res_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converts a Keras model to dot format and save to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(res_model, to_file=FILES_GENERATED + MODEL_PNG, show_shapes=True, show_layer_names=True)\n",
    "display(Image.open(FILES_GENERATED + MODEL_PNG))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = CHECKPOINT_DIR + \"cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5*BATCH_SIZE)\n",
    "\n",
    "# Create a callback allowing to save the best performing model\n",
    "checkpoint = ModelCheckpoint(MODEL_SAVED, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "history = res_model.fit(train,epochs=30, \n",
    "                    validation_data=validation,\n",
    "                    steps_per_epoch=100,\n",
    "                    callbacks=[early_stopping,lr, checkpoint],\n",
    "                    batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy & Loss each epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the training artifacts\n",
    "fig , ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(20, 10)\n",
    "\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "ax[0].plot(epochs, train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'yo-' , label = 'Validation Accuracy')\n",
    "ax[0].set_title('Model Train & Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "\n",
    "ax[1].plot(epochs, train_loss , 'go-' , label = 'Training Loss')\n",
    "ax[1].plot(epochs, val_loss , 'yo-' , label = 'Validation Loss')\n",
    "ax[1].set_title('Model Train & Validation Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation with training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on train and test\n",
    "score = res_model.evaluate(train)\n",
    "\n",
    "print(\"Train Loss: \", score[0])\n",
    "print(\"Train Accuracy: \", score[1])\n",
    "\n",
    "score = res_model.evaluate(test)\n",
    "print(\"\\nTest loss: \", score[0])\n",
    "print(\"Test Accuracy: \", score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(MODEL_SAVED)\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the restored model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = new_model.evaluate(test)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the restored model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img1 = 'chest_xray/test/NORMAL/IM-0029-0001.jpeg'\n",
    "test_img2 = 'chest_xray/train/PNEUMONIA/person1_bacteria_1.jpeg'\n",
    "test_img3 = 'chest_xray/val/NORMAL/NORMAL2-IM-1427-0001.jpeg'\n",
    "\n",
    "list_images = [test_img1, test_img2, test_img3]\n",
    "\n",
    "for load_img in list_images:\n",
    "    img = tf.keras.utils.load_img(\n",
    "        load_img, target_size=(224, 224)\n",
    "    )\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = new_model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "<p> Our model has an accuracy of 95.8% on the validation set. // todo: check %\n",
    "\n",
    "On the hold out dataset, the model is performing with an F-Score of 0.91 but what really matters is that it has a recall of 96%!\n",
    "\n",
    "Meaning that we're not detecting 4% of the malignant patient. On the test dataset, out of 390 malignant patients, the model detected 378 pneumonia.\n",
    "\n",
    "The trade off is that our model predicted that 27.7% of patient had pneumonia where in fact they were healthy (False Positive). </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
