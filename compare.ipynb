{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import glob\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from PIL import Image\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import cv2 as cv\n",
    "from keras.utils import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=\"chest_Xray/\"\n",
    "train_directory= input_data + \"train/\"\n",
    "val_directory= input_data + \"val/\"\n",
    "test_directory= input_data + \"test/\"\n",
    "\n",
    "data_dir = train_directory\n",
    "class_names=os.listdir(train_directory)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_model_accuracy(train_folder, validation_folder, batch_size, image_size, optimizer, epochs):\n",
    "    # print(\"Evaluating \" + param_evaluated)\n",
    "\n",
    "    # Prepare iterators\n",
    "    datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "    train_it = datagen.flow_from_directory(directory=train_folder,\n",
    "                                           class_mode='binary', batch_size=batch_size,\n",
    "                                           target_size=(image_size, image_size))\n",
    "    val_it = datagen.flow_from_directory(directory=validation_folder,\n",
    "                                         class_mode='binary', batch_size=batch_size,\n",
    "                                         target_size=(image_size, image_size))\n",
    "    test_it = datagen.flow_from_directory(test_directory,\n",
    "                                          class_mode='binary', batch_size=batch_size,\n",
    "                                          target_size=(image_size, image_size))\n",
    "\n",
    "    # create model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(image_size, image_size, 3)))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define learning rate scheduler\n",
    "    def lr_scheduler(epoch):\n",
    "        lr = 0.001\n",
    "        if epoch > 10:\n",
    "            lr = 0.0001\n",
    "        return lr\n",
    "\n",
    "    # Create learning rate scheduler callback\n",
    "    lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_it,\n",
    "              validation_data=val_it,\n",
    "              steps_per_epoch=train_it.n // train_it.batch_size,\n",
    "              validation_steps=val_it.n // val_it.batch_size,\n",
    "              epochs=epochs, verbose=1,\n",
    "              callbacks=[lr_scheduler_callback])\n",
    "\n",
    "    # Evaluate model\n",
    "    _, acc = model.evaluate(test_it, steps=len(test_it), verbose=1)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(train_folder, validation_folder, batch_size, image_size, optimizer, epochs):\n",
    "    # Prepare iterators\n",
    "    datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "    train_it = datagen.flow_from_directory(directory=train_folder,\n",
    "                                           class_mode='binary', batch_size=batch_size,\n",
    "                                           target_size=(image_size, image_size))\n",
    "    val_it = datagen.flow_from_directory(directory=validation_folder,\n",
    "                                         class_mode='binary', batch_size=batch_size,\n",
    "                                         target_size=(image_size, image_size))\n",
    "    test_it = datagen.flow_from_directory(test_directory,\n",
    "                                          class_mode='binary', batch_size=batch_size,\n",
    "                                          target_size=(image_size, image_size))\n",
    "\n",
    "    # create model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(image_size, image_size, 3)))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define learning rate scheduler\n",
    "    def lr_scheduler(epoch):\n",
    "        lr = 0.001\n",
    "        if epoch > 10:\n",
    "            lr = 0.0001\n",
    "        return lr\n",
    "\n",
    "    # Create learning rate scheduler callback\n",
    "    lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_it,\n",
    "              validation_data=val_it,\n",
    "              steps_per_epoch=train_it.n // train_it.batch_size,\n",
    "              validation_steps=val_it.n // val_it.batch_size,\n",
    "              epochs=epochs, verbose=1,\n",
    "              callbacks=[lr_scheduler_callback])\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_128 = 128\n",
    "BATCH_SIZE_64 = 64\n",
    "BATCH_SIZE_32 = 32\n",
    "batch_size_array = [BATCH_SIZE_128, BATCH_SIZE_64, BATCH_SIZE_32]\n",
    "\n",
    "OPTIMIZER_ADAM = 'adam'\n",
    "OPTIMIZER_SGD = 'sgd'\n",
    "OPTIMIZER_RMSPROP= 'rmsprop'\n",
    "optimizer_array = [OPTIMIZER_ADAM, OPTIMIZER_SGD, OPTIMIZER_RMSPROP]\n",
    "\n",
    "EPOCHS_5 = 5\n",
    "EPOCHS_10 = 10\n",
    "EPOCHS_20 = 20\n",
    "epoch_array = [EPOCHS_5, EPOCHS_10, EPOCHS_20]\n",
    "\n",
    "# Common image sizes include 64x64, 128x128, 28x28 (MNIST), and 224x224 (VGG-16).\n",
    "IMAGE_SIZE_128 = 128\n",
    "IMAGE_SIZE_64 = 64\n",
    "IMAGE_SIZE_28 = 28\n",
    "image_size_array = [IMAGE_SIZE_128, IMAGE_SIZE_64, IMAGE_SIZE_28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'batch_size': batch_size_array,\n",
    "    'image_size': image_size_array,\n",
    "    'optimizer': optimizer_array,\n",
    "    'epochs': epoch_array\n",
    "}\n",
    "\n",
    "\n",
    "# Perform grid search\n",
    "best_acc = 0.0\n",
    "best_params = {}\n",
    "for batch_size in param_grid['batch_size']:\n",
    "    print(\"Evaluating batch_size:\", batch_size)\n",
    "    for image_size in param_grid['image_size']:\n",
    "        print(\"Evaluating image_size:\", image_size)\n",
    "        for optimizer in param_grid['optimizer']:\n",
    "            print(\"Evaluating optimizer:\", optimizer)\n",
    "            for epochs in param_grid['epochs']:\n",
    "                print(\"Evaluating epochs:\", epochs)\n",
    "                acc = get_model_accuracy(train_directory, val_directory, batch_size, image_size,\n",
    "                                         optimizer, epochs)\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_params = {'batch_size': batch_size, 'image_size': image_size,\n",
    "                                   'optimizer': optimizer, 'epochs': epochs}\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best accuracy:\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 64, 'image_size': 128, 'optimizer': 'sgd', 'epochs': 5}\n",
      "Best accuracy: 0.8301281929016113\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best accuracy:\", best_acc)\n",
    "\n",
    "# Best parameters: {'batch_size': 64, 'image_size': 128, 'optimizer': 'sgd', 'epochs': 5}\n",
    "# Best accuracy: 0.8301281929016113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 17 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "81/81 [==============================] - 37s 450ms/step - loss: 0.4843 - accuracy: 0.7727 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "81/81 [==============================] - 37s 459ms/step - loss: 0.3337 - accuracy: 0.8736 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "81/81 [==============================] - 36s 450ms/step - loss: 0.2741 - accuracy: 0.9028 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "81/81 [==============================] - 36s 440ms/step - loss: 0.2398 - accuracy: 0.9185 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "81/81 [==============================] - 35s 437ms/step - loss: 0.2098 - accuracy: 0.9299 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "best_model, history = get_model(train_directory, val_directory, best_params['batch_size'], best_params['image_size'], best_params['optimizer'], best_params['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.3603 - accuracy: 0.8317\n",
      "Accuracy on test set: 83.173\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "test_it = datagen.flow_from_directory(test_directory,\n",
    "                                          class_mode='binary', batch_size=best_params['batch_size'],\n",
    "                                          target_size=(best_params['image_size'], best_params['image_size']))\n",
    "\n",
    "_, accuracy = best_model.evaluate(test_it, steps=len(test_it), verbose=1)\n",
    "\n",
    "print('Accuracy on test set: %.3f' % (accuracy * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zoidberg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
